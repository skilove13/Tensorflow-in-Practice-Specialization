{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week2_CNN_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuNMdp7et3GgDyxP8dXAs8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skilove13/Tensorflow-in-Practice-Specialization/blob/master/Week2_CNN_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYWsxJVljIo8",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/oddrationale/mnist-in-csv\n",
        "\n",
        "The MNIST dataset provided in a easy-to-use CSV format\n",
        "The original dataset is in a format that is difficult for beginners to use. This dataset uses the work of Joseph Redmon to provide the MNIST dataset in a CSV format.\n",
        "\n",
        "The dataset consists of two files:\n",
        "\n",
        "mnist_train.csv\n",
        "mnist_test.csv\n",
        "The mnist_train.csv file contains the 60,000 training examples and labels. The mnist_test.csv contains 10,000 test examples and labels. Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqL8ISDWiFsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "924dc30c-53ef-4b32-f0b8-b8dc85da5232"
      },
      "source": [
        "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
        "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
        "# ATTENTION: Please use the provided epoch values when training.\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from os import getcwd\n",
        "\n",
        "def get_data(filename):\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the label\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "    with open(filename) as training_file:\n",
        "        # Your code starts here\n",
        "        data = np.genfromtxt(filename, delimiter=',')\n",
        "        labels = data[1:,0]\n",
        "        images = data[1:,1:785]\n",
        "        images = images.reshape((images.shape[0], 28, 28))\n",
        "        #labels = []\n",
        "        #images_buf = []\n",
        "        #images = []\n",
        "        #a = csv.reader(training_file, delimiter = ',')\n",
        "        #for row in a:\n",
        "        #    labels.append(row[0])\n",
        "        #    images_buf.append(row[1:])\n",
        "        #labels = np.array(labels[1:])\n",
        "        #images2 = np.array(images[1:][:])\n",
        "        #y, x = np.shape(images2)\n",
        "        #images = np.reshape(images2, (y, 28, 28))\n",
        "      # Your code ends here\n",
        "    return images, labels \n",
        "\n",
        "path_sign_mnist_train = f\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\n",
        "path_sign_mnist_test = f\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\n",
        "training_images, training_labels = get_data(path_sign_mnist_train)\n",
        "testing_images, testing_labels = get_data(path_sign_mnist_test)\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-679d821998b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mpath_sign_mnist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mpath_sign_mnist_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_sign_mnist_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_sign_mnist_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-679d821998b1>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;31m# You are reading in strings, but need the values to be floats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# Check out np.array().astype for a conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Your code starts here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/../tmp2/sign_mnist_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSMNoL6ViiNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this section you will have to add another dimension to the data\n",
        "# So, for example, if your array is (10000, 28, 28)\n",
        "# You will need to make it (10000, 28, 28, 1)\n",
        "# Hint: np.expand_dims\n",
        "\n",
        "training_images = training_images.reshape((training_images.shape[0], training_images.shape[1], training_images.shape[2], 1))# Your Code Here\n",
        "testing_images = testing_images.reshape((testing_images.shape[0], testing_images.shape[1], testing_images.shape[2], 1))# Your Code Here\n",
        "\n",
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'nearest'\n",
        "    # Your Code Here\n",
        "    )\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    # Your Code Here)\n",
        "    \n",
        "# Keep These\n",
        "print(training_images.shape)\n",
        "print(testing_images.shape)\n",
        "    \n",
        "# Their output should be:\n",
        "# (27455, 28, 28, 1)\n",
        "# (7172, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sYRYNhPile-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "# Use no more than 2 Conv2D and 2 MaxPooling2D\n",
        "model = tf.keras.models.Sequential([# Your Code Here\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile Model. \n",
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])# Your Code Here)\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit_generator(# Your Code Here (set 'epochs' = 2)\n",
        "                              train_datagen.flow(training_images,training_labels,batch_size=32),\n",
        "                              #steps_per_epoch = len(training_images) / 32,\n",
        "                              #steps_per_epoch = 100,\n",
        "                              epochs=2,\n",
        "                              validation_data= validation_datagen.flow(testing_images,testing_labels, batch_size=32),\n",
        "                              verbose = 1)\n",
        "                              #validation_steps = len(testing_images) / 32)\n",
        "\n",
        "model.evaluate(testing_images, testing_labels, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rorblg_Zin-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy'] # Your Code Here\n",
        "val_acc = history.history['val_accuracy'] # Your Code Here\n",
        "loss = history.history['loss']# Your Code Here\n",
        "val_loss = history.history['val_loss']# Your Code Here\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}